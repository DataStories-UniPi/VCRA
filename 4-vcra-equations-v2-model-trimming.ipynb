{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import sys, os\n",
    "import sklearn\n",
    "import datetime\n",
    "\n",
    "import importlib\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import st_toolkit as geohl\n",
    "importlib.reload(geohl)\n",
    "\n",
    "import cri_calc as cri\n",
    "importlib.reload(cri)\n",
    "\n",
    "import cri_helper as helper\n",
    "importlib.reload(helper)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def calculate_cri(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r = cri.colregs_alarms(own=own, target=target)\n",
    "    ves_cri = cri.calculate_cri(own, target, ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r)\n",
    "    \n",
    "    return ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r, ves_cri"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def calculate_cri_timeslice(df):\n",
    "    timeslice_result = []\n",
    "    \n",
    "    for row_i in df.itertuples():\n",
    "        for row_j in df.itertuples():\n",
    "            if row_i.Index == row_j.Index:\n",
    "                continue\n",
    "                \n",
    "            timeslice_result.append([row_i.Index, row_i.mmsi, row_i.geom, row_i.speed, row_i.course, \n",
    "                                     row_j.Index, row_j.mmsi, row_j.geom, row_j.speed, row_j.course, *calculate_cri(row_i, row_j)])\n",
    "            \n",
    "#     return pd.DataFrame(timeslice_result, columns=['own', 'target', 'dcpa', 'tcpa', 'hr', 'rel_movement_angle', 'dist_euclid', 'speed_r', 'cri'])\n",
    "    return pd.DataFrame(timeslice_result, columns=['own_Index', 'own_mmsi', 'own_geom', 'own_speed', 'own_course',\n",
    "                                                   'target_Index', 'target_mmsi', 'target_geom', 'target_speed', 'target_course', \n",
    "                                                   'dcpa', 'tcpa', 'hr', 'rel_movement_angle', 'dist_euclid', 'speed_r', 'cri'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df = pd.read_csv('./data/unipi_ais_dynamic_jul2018_1w_algn_linear_v2_w_lens.csv', parse_dates=['datetime'])\n",
    "gdf = geohl.getGeoDataFrame_v2(df, crs='epsg:4326')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrewt/miniconda3/envs/vesai/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:122: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "gdf2 = gdf.loc[gdf.datetime.dt.date.between(datetime.date(2018, 7, 3), datetime.date(2018, 7, 3), inclusive='both')].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "gdf_sub_moving = gdf2.loc[gdf2.speed.between(1, 50, inclusive='neither')].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Training Dataset"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tqdm.pandas()\n",
    "# gdf_vcra = gdf_sub_moving.groupby(['datetime']).progress_apply(lambda l: calculate_cri_timeslice(l.copy()))"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def applyParallel(dfGrouped, func, n_jobs=-1):\n",
    "    '''\n",
    "    Forked from: https://stackoverflow.com/a/27027632\n",
    "    '''\n",
    "    n_jobs = multiprocessing.cpu_count() if n_jobs == -1 else n_jobs\n",
    "    print(f'Scaling {func} to {n_jobs} CPUs')\n",
    "    \n",
    "    retLst = Parallel(n_jobs=n_jobs)(delayed(func)(group) for name, group in tqdm(dfGrouped))\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "\n",
    "gdf_vcra = applyParallel(gdf_sub_moving.groupby(['datetime']), lambda l: calculate_cri_timeslice(l.copy()), 7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gdf_vcra_mi = gdf_vcra.copy()\n",
    "gdf_vcra_mi = pd.merge(gdf_vcra_mi, gdf_sub_moving.datetime, left_on='own_Index', right_index=True)\n",
    "gdf_vcra_mi.set_index(['datetime'], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gdf_vcra_mi.to_pickle('./data/unipi_ais_dynamic_jul2018_1w_vcra_dataset_v3.pickle')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training an MLP (via sklearn) -- Prototype"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "gdf_vcra = pd.read_pickle('./data/unipi_ais_dynamic_jul2018_1w_vcra_dataset_v3.pickle')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tqdm.pandas(desc='Adding Vessels\\' Length...')\n",
    "\n",
    "# gdf_vcra.loc[:, 'own_length'] = gdf_vcra.own_Index.apply(lambda l: gdf_sub_moving[l].length)\n",
    "mlp_input = gdf_vcra.loc[gdf_vcra.own_Index.isin(gdf_sub_moving.index.values)].copy()\n",
    "mlp_input.loc[:, 'own_length'] = mlp_input.own_Index.progress_apply(lambda l: gdf_sub_moving.loc[l].length)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Adding Vessels' Length...: 100%|██████| 960268/960268 [01:44<00:00, 9166.56it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X = mlp_input[['dist_euclid', 'own_speed', 'target_speed', 'own_course', 'target_course', 'own_length']].values\n",
    "y = mlp_input[['cri']].values.ravel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# regr = MLPRegressor(random_state=10, max_iter=500, hidden_layer_sizes=(128,64), \n",
    "#                     verbose=True, early_stopping=True, n_iter_no_change=10).fit(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "regr = MLPRegressor(random_state=10, max_iter=30, hidden_layer_sizes=(256, 32), \n",
    "                    verbose=True, early_stopping=True, n_iter_no_change=10).fit(X_train_norm, y_train)\n",
    "\n",
    "regr.score(scaler.transform(X_test), y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.00385015\n",
      "Validation score: 0.644050\n",
      "Iteration 2, loss = 0.00259088\n",
      "Validation score: 0.725855\n",
      "Iteration 3, loss = 0.00230187\n",
      "Validation score: 0.744237\n",
      "Iteration 4, loss = 0.00216573\n",
      "Validation score: 0.778982\n",
      "Iteration 5, loss = 0.00204967\n",
      "Validation score: 0.780121\n",
      "Iteration 6, loss = 0.00198630\n",
      "Validation score: 0.758965\n",
      "Iteration 7, loss = 0.00190444\n",
      "Validation score: 0.784247\n",
      "Iteration 8, loss = 0.00183911\n",
      "Validation score: 0.790634\n",
      "Iteration 9, loss = 0.00179812\n",
      "Validation score: 0.808164\n",
      "Iteration 10, loss = 0.00176251\n",
      "Validation score: 0.805912\n",
      "Iteration 11, loss = 0.00172066\n",
      "Validation score: 0.831105\n",
      "Iteration 12, loss = 0.00168713\n",
      "Validation score: 0.824960\n",
      "Iteration 13, loss = 0.00164822\n",
      "Validation score: 0.827729\n",
      "Iteration 14, loss = 0.00162294\n",
      "Validation score: 0.831060\n",
      "Iteration 15, loss = 0.00158726\n",
      "Validation score: 0.835460\n",
      "Iteration 16, loss = 0.00156929\n",
      "Validation score: 0.838889\n",
      "Iteration 17, loss = 0.00154823\n",
      "Validation score: 0.834683\n",
      "Iteration 18, loss = 0.00152200\n",
      "Validation score: 0.838771\n",
      "Iteration 19, loss = 0.00150440\n",
      "Validation score: 0.844067\n",
      "Iteration 20, loss = 0.00148720\n",
      "Validation score: 0.830301\n",
      "Iteration 21, loss = 0.00146330\n",
      "Validation score: 0.853514\n",
      "Iteration 22, loss = 0.00144792\n",
      "Validation score: 0.846411\n",
      "Iteration 23, loss = 0.00143354\n",
      "Validation score: 0.851350\n",
      "Iteration 24, loss = 0.00142083\n",
      "Validation score: 0.854658\n",
      "Iteration 25, loss = 0.00140232\n",
      "Validation score: 0.835063\n",
      "Iteration 26, loss = 0.00139186\n",
      "Validation score: 0.844484\n",
      "Iteration 27, loss = 0.00136806\n",
      "Validation score: 0.864906\n",
      "Iteration 28, loss = 0.00136654\n",
      "Validation score: 0.869035\n",
      "Iteration 29, loss = 0.00136144\n",
      "Validation score: 0.860629\n",
      "Iteration 30, loss = 0.00134410\n",
      "Validation score: 0.858902\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrewt/miniconda3/envs/vesai/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.868270934890964"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "cri_pred = pd.Series(regr.predict(scaler.transform(X_test))).clip(0,1).values\n",
    "print(f'MAE: {mean_absolute_error(y_test, cri_pred)}')\n",
    "print(f'RMSE: {mean_squared_error(y_test, cri_pred, squared=False)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 0.01787829212857179\n",
      "RMSE: 0.04847896187973707\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from joblib import dump, load\n",
    "dump(regr, './data/vcra-1w-mlp-hidden_256_32.joblib') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating ML model timeliness"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def ml_calc_cri_timeslice(df, **kwargs):\n",
    "    timeslice_result = []\n",
    "    \n",
    "    for row_i in df.itertuples():\n",
    "        for row_j in df.itertuples():\n",
    "            if row_i.Index == row_j.Index:\n",
    "                continue\n",
    "                \n",
    "            timeslice_result.append([row_i.Index, row_i.mmsi, row_i.geom, row_i.speed, row_i.course, \n",
    "                                     row_j.Index, row_j.mmsi, row_j.geom, row_j.speed, row_j.course, *ml_calc_cri(row_i, row_j, **kwargs)])\n",
    "            \n",
    "#     return pd.DataFrame(timeslice_result, columns=['own', 'target', 'dcpa', 'tcpa', 'hr', 'rel_movement_angle', 'dist_euclid', 'speed_r', 'cri'])\n",
    "    return pd.DataFrame(timeslice_result, columns=['own_Index', 'own_mmsi', 'own_geom', 'own_speed', 'own_course',\n",
    "                                                   'target_Index', 'target_mmsi', 'target_geom', 'target_speed', 'target_course', \n",
    "                                                   'dist_euclid', 'cri'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def ml_calc_cri(rec_own, rec_target, model=None, model_fun=calculate_cri, model_norm=None):\n",
    "    own = rec_own\n",
    "    target = rec_target\n",
    "    \n",
    "    if model is None:\n",
    "        _, _, _, _, dist_euclid, _, ves_cri = model_fun(own, target)\n",
    "    else:\n",
    "        dist_euclid, model_input = model_fun(own, target)\n",
    "        ves_cri = model.predict(model_norm.transform(np.array(model_input).reshape(1, -1)))\n",
    "    \n",
    "    return dist_euclid, min(max(ves_cri[0], 0), 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def ml_calc_cri_ours(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    own_geom_nm, target_geom_nm = map(helper.angular_to_nautical_miles, [own['geom'], target['geom']])\n",
    "    xr, yr = helper.calculate_delta(own_geom_nm.x, target_geom_nm.x), helper.calculate_delta(own_geom_nm.y, target_geom_nm.y)\n",
    "    hr = helper.calculate_delta(own['course'], target['course'])\n",
    "    \n",
    "    # Get vessels' Euclidean Distance -- NAUTICAL MILES\n",
    "    dist_euclid = np.sqrt(xr**2 + yr**2)\n",
    "    \n",
    "    return dist_euclid, [dist_euclid, own['speed'], target['speed'], own['course'], target['course'], own['length']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from joblib import dump, load\n",
    "regr_ours = load('./data/vcra-1w-mlp-hidden_256_32.joblib') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "grouped = gdf_sub_moving.groupby(['datetime'])\n",
    "l = grouped.get_group((list(grouped.groups)[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "%%timeit \n",
    "ml_calc_cri_timeslice(l.copy(), model=regr_ours, model_fun=ml_calc_cri_ours, model_norm=scaler);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "311 ms ± 1.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26a0fb21edfd8898ccaa2d3be90ad05e47a6ebc73217c056c6f09f953e946973"
  },
  "kernelspec": {
   "display_name": "Python (VesselAI)",
   "language": "python",
   "name": "vesai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}