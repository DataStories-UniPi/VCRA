{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import sys, os\n",
    "import sklearn\n",
    "import datetime\n",
    "\n",
    "import importlib\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import st_toolkit as geohl\n",
    "importlib.reload(geohl)\n",
    "\n",
    "import cri_calc as cri\n",
    "importlib.reload(cri)\n",
    "\n",
    "import cri_helper as helper\n",
    "importlib.reload(helper)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def calculate_cri(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r = cri.colregs_alarms(own=own, target=target)\n",
    "    ves_cri = cri.calculate_cri(own, target, ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r)\n",
    "    \n",
    "    return ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r, ves_cri"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def calculate_cri_timeslice(df):\n",
    "    timeslice_result = []\n",
    "    \n",
    "    for row_i in df.itertuples():\n",
    "        for row_j in df.itertuples():\n",
    "            if row_i.Index == row_j.Index:\n",
    "                continue\n",
    "                \n",
    "            timeslice_result.append([row_i.Index, row_i.mmsi, row_i.geom, row_i.speed, row_i.course, \n",
    "                                     row_j.Index, row_j.mmsi, row_j.geom, row_j.speed, row_j.course, *calculate_cri(row_i, row_j)])\n",
    "            \n",
    "#     return pd.DataFrame(timeslice_result, columns=['own', 'target', 'dcpa', 'tcpa', 'hr', 'rel_movement_angle', 'dist_euclid', 'speed_r', 'cri'])\n",
    "    return pd.DataFrame(timeslice_result, columns=['own_Index', 'own_mmsi', 'own_geom', 'own_speed', 'own_course',\n",
    "                                                   'target_Index', 'target_mmsi', 'target_geom', 'target_speed', 'target_course', \n",
    "                                                   'dcpa', 'tcpa', 'hr', 'rel_movement_angle', 'dist_euclid', 'speed_r', 'cri'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def ml_calc_cri(rec_own, rec_target, model=None, model_fun=calculate_cri, model_norm=None):\n",
    "    own = rec_own\n",
    "    target = rec_target\n",
    "    \n",
    "    if model is None:\n",
    "        _, _, _, _, dist_euclid, _, ves_cri = model_fun(own, target)\n",
    "    else:\n",
    "        dist_euclid, model_input = model_fun(own, target)\n",
    "        ves_cri = model.predict(model_norm.transform(np.array(model_input).reshape(1, -1)))\n",
    "    \n",
    "    return dist_euclid, min(max(ves_cri[0], 0), 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def ml_calc_cri_timeslice(df, **kwargs):\n",
    "    timeslice_result = []\n",
    "    \n",
    "    for row_i in df.itertuples():\n",
    "        for row_j in df.itertuples():\n",
    "            if row_i.Index == row_j.Index:\n",
    "                continue\n",
    "                \n",
    "            timeslice_result.append([row_i.Index, row_i.mmsi, row_i.geom, row_i.speed, row_i.course, \n",
    "                                     row_j.Index, row_j.mmsi, row_j.geom, row_j.speed, row_j.course, *ml_calc_cri(row_i, row_j, **kwargs)])\n",
    "            \n",
    "#     return pd.DataFrame(timeslice_result, columns=['own', 'target', 'dcpa', 'tcpa', 'hr', 'rel_movement_angle', 'dist_euclid', 'speed_r', 'cri'])\n",
    "    return pd.DataFrame(timeslice_result, columns=['own_Index', 'own_mmsi', 'own_geom', 'own_speed', 'own_course',\n",
    "                                                   'target_Index', 'target_mmsi', 'target_geom', 'target_speed', 'target_course', \n",
    "                                                   'dist_euclid', 'cri'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df = pd.read_csv('./data/unipi_ais_dynamic_jul2018_1w_algn_linear_v2_w_lens.csv', parse_dates=['datetime'])\n",
    "gdf = geohl.getGeoDataFrame_v2(df, crs='epsg:4326')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrewt/miniconda3/envs/vesai/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:122: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "gdf2 = gdf.loc[gdf.datetime.dt.date.between(datetime.date(2018, 7, 3), datetime.date(2018, 7, 3), inclusive='both')].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "gdf_sub_moving = gdf2.loc[gdf2.speed.between(1, 50, inclusive='neither')].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "gdf_vcra = pd.read_pickle('./data/unipi_ais_dynamic_jul2018_1w_vcra_dataset_v3.pickle')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tqdm.pandas(desc='Adding Vessels\\' Length...')\n",
    "\n",
    "# gdf_vcra.loc[:, 'own_length'] = gdf_vcra.own_Index.apply(lambda l: gdf_sub_moving[l].length)\n",
    "mlp_input = gdf_vcra.loc[gdf_vcra.own_Index.isin(gdf_sub_moving.index.values)].copy()\n",
    "mlp_input.loc[:, 'own_length'] = mlp_input.own_Index.progress_apply(lambda l: gdf_sub_moving.loc[l].length)\n",
    "mlp_input.loc[:, 'target_length'] = mlp_input.target_Index.progress_apply(lambda l: gdf_sub_moving.loc[l].length)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Adding Vessels' Length...: 100%|██████| 960268/960268 [01:38<00:00, 9757.46it/s]\n",
      "Adding Vessels' Length...: 100%|██████| 960268/960268 [01:37<00:00, 9865.41it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "grouped = gdf_sub_moving.groupby(['datetime'])\n",
    "l = grouped.get_group((list(grouped.groups)[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating EQ model timeliness"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def calculate_cri(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r = cri.colregs_alarms(own=own, target=target)\n",
    "    ves_cri = cri.calculate_cri(own, target, ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r)\n",
    "    \n",
    "    return ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r, ves_cri"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "%%timeit \n",
    "ml_calc_cri_timeslice(l.copy(), model=None, model_fun=calculate_cri, model_norm=None);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "329 ms ± 11.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare with Park et al."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from skrvm import RVR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X = mlp_input[['dist_euclid', 'hr', 'own_speed', 'target_speed', 'own_course', 'target_course', 'own_length', 'target_length']].copy()\n",
    "X = X.values\n",
    "y = mlp_input[['cri']].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "n_samples = 15000\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "clf = RVR(kernel='rbf', verbose=False, n_iter=100)\n",
    "clf.fit(X_train_norm[:n_samples].astype(float), y_train[:n_samples].astype(float))\n",
    "\n",
    "clf.score(scaler.transform(X_test[:n_samples]), y_test[:n_samples])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6238591791371839"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "cri_pred_rvm = pd.Series(clf.predict(scaler.transform(X_test[:n_samples]))).clip(0,1).values\n",
    "print(f'MAE: {mean_absolute_error(y_test[:n_samples], cri_pred_rvm)}')\n",
    "print(f'RMSE: {mean_squared_error(y_test[:n_samples], cri_pred_rvm, squared=False)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 0.03589468107012043\n",
      "RMSE: 0.08018135415141722\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from joblib import dump, load\n",
    "dump(clf, './data/park-et-al-rvm-vcra-v2.joblib') "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./data/park-et-al-rvm-vcra-v2.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def ml_calc_cri_park_etal(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    own_geom_nm, target_geom_nm = map(helper.angular_to_nautical_miles, [own['geom'], target['geom']])\n",
    "    xr, yr = helper.calculate_delta(own_geom_nm.x, target_geom_nm.x), helper.calculate_delta(own_geom_nm.y, target_geom_nm.y)\n",
    "    hr = helper.calculate_delta(own['course'], target['course'])\n",
    "    \n",
    "    # Get vessels' Euclidean Distance -- NAUTICAL MILES\n",
    "    dist_euclid = np.sqrt(xr**2 + yr**2)\n",
    "    \n",
    "    return dist_euclid, [dist_euclid, hr, own['speed'], target['speed'], own['course'], target['course'], own['length'], target['length']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "%%timeit \n",
    "ml_calc_cri_timeslice(l.copy(), model=clf, model_fun=ml_calc_cri_park_etal, model_norm=scaler);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "322 ms ± 744 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare with Li et al."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = mlp_input[['speed_r', 'hr', 'rel_movement_angle', 'dist_euclid']].values\n",
    "y = mlp_input[['cri']].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "regr_li_et_al = MLPRegressor(random_state=10, max_iter=100, hidden_layer_sizes=(54,), \n",
    "                    verbose=True, early_stopping=True, n_iter_no_change=10).fit(X_train_norm, y_train)\n",
    "\n",
    "regr_li_et_al.score(scaler.transform(X_test), y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.00771154\n",
      "Validation score: 0.306641\n",
      "Iteration 2, loss = 0.00602272\n",
      "Validation score: 0.368845\n",
      "Iteration 3, loss = 0.00565975\n",
      "Validation score: 0.397446\n",
      "Iteration 4, loss = 0.00544266\n",
      "Validation score: 0.410982\n",
      "Iteration 5, loss = 0.00532874\n",
      "Validation score: 0.426659\n",
      "Iteration 6, loss = 0.00523985\n",
      "Validation score: 0.434547\n",
      "Iteration 7, loss = 0.00514796\n",
      "Validation score: 0.445652\n",
      "Iteration 8, loss = 0.00506979\n",
      "Validation score: 0.446137\n",
      "Iteration 9, loss = 0.00500152\n",
      "Validation score: 0.463181\n",
      "Iteration 10, loss = 0.00495039\n",
      "Validation score: 0.463726\n",
      "Iteration 11, loss = 0.00493066\n",
      "Validation score: 0.467641\n",
      "Iteration 12, loss = 0.00489548\n",
      "Validation score: 0.470993\n",
      "Iteration 13, loss = 0.00487533\n",
      "Validation score: 0.474716\n",
      "Iteration 14, loss = 0.00484915\n",
      "Validation score: 0.478858\n",
      "Iteration 15, loss = 0.00482946\n",
      "Validation score: 0.478854\n",
      "Iteration 16, loss = 0.00480419\n",
      "Validation score: 0.483486\n",
      "Iteration 17, loss = 0.00479257\n",
      "Validation score: 0.460017\n",
      "Iteration 18, loss = 0.00477592\n",
      "Validation score: 0.467670\n",
      "Iteration 19, loss = 0.00476100\n",
      "Validation score: 0.483005\n",
      "Iteration 20, loss = 0.00474365\n",
      "Validation score: 0.473405\n",
      "Iteration 21, loss = 0.00473159\n",
      "Validation score: 0.479330\n",
      "Iteration 22, loss = 0.00471996\n",
      "Validation score: 0.470113\n",
      "Iteration 23, loss = 0.00471798\n",
      "Validation score: 0.493623\n",
      "Iteration 24, loss = 0.00470132\n",
      "Validation score: 0.490500\n",
      "Iteration 25, loss = 0.00468815\n",
      "Validation score: 0.491051\n",
      "Iteration 26, loss = 0.00467405\n",
      "Validation score: 0.494507\n",
      "Iteration 27, loss = 0.00466059\n",
      "Validation score: 0.480637\n",
      "Iteration 28, loss = 0.00464734\n",
      "Validation score: 0.498712\n",
      "Iteration 29, loss = 0.00463961\n",
      "Validation score: 0.497820\n",
      "Iteration 30, loss = 0.00462409\n",
      "Validation score: 0.501451\n",
      "Iteration 31, loss = 0.00462346\n",
      "Validation score: 0.501010\n",
      "Iteration 32, loss = 0.00461553\n",
      "Validation score: 0.494436\n",
      "Iteration 33, loss = 0.00461342\n",
      "Validation score: 0.505457\n",
      "Iteration 34, loss = 0.00460728\n",
      "Validation score: 0.502458\n",
      "Iteration 35, loss = 0.00460504\n",
      "Validation score: 0.499520\n",
      "Iteration 36, loss = 0.00460559\n",
      "Validation score: 0.503051\n",
      "Iteration 37, loss = 0.00459676\n",
      "Validation score: 0.496711\n",
      "Iteration 38, loss = 0.00459802\n",
      "Validation score: 0.504639\n",
      "Iteration 39, loss = 0.00459217\n",
      "Validation score: 0.488889\n",
      "Iteration 40, loss = 0.00459183\n",
      "Validation score: 0.502844\n",
      "Iteration 41, loss = 0.00459418\n",
      "Validation score: 0.484240\n",
      "Iteration 42, loss = 0.00459077\n",
      "Validation score: 0.507569\n",
      "Iteration 43, loss = 0.00459072\n",
      "Validation score: 0.506642\n",
      "Iteration 44, loss = 0.00458242\n",
      "Validation score: 0.508294\n",
      "Iteration 45, loss = 0.00458337\n",
      "Validation score: 0.506235\n",
      "Iteration 46, loss = 0.00458087\n",
      "Validation score: 0.503211\n",
      "Iteration 47, loss = 0.00457453\n",
      "Validation score: 0.497176\n",
      "Iteration 48, loss = 0.00456933\n",
      "Validation score: 0.504616\n",
      "Iteration 49, loss = 0.00456726\n",
      "Validation score: 0.491247\n",
      "Iteration 50, loss = 0.00456998\n",
      "Validation score: 0.506826\n",
      "Iteration 51, loss = 0.00456563\n",
      "Validation score: 0.483156\n",
      "Iteration 52, loss = 0.00456477\n",
      "Validation score: 0.506916\n",
      "Iteration 53, loss = 0.00456045\n",
      "Validation score: 0.510401\n",
      "Iteration 54, loss = 0.00455991\n",
      "Validation score: 0.506579\n",
      "Iteration 55, loss = 0.00455948\n",
      "Validation score: 0.507872\n",
      "Iteration 56, loss = 0.00455073\n",
      "Validation score: 0.504063\n",
      "Iteration 57, loss = 0.00455724\n",
      "Validation score: 0.492013\n",
      "Iteration 58, loss = 0.00455314\n",
      "Validation score: 0.508184\n",
      "Iteration 59, loss = 0.00455221\n",
      "Validation score: 0.511158\n",
      "Iteration 60, loss = 0.00454794\n",
      "Validation score: 0.500929\n",
      "Iteration 61, loss = 0.00455049\n",
      "Validation score: 0.501487\n",
      "Iteration 62, loss = 0.00454816\n",
      "Validation score: 0.507871\n",
      "Iteration 63, loss = 0.00454681\n",
      "Validation score: 0.503182\n",
      "Iteration 64, loss = 0.00454741\n",
      "Validation score: 0.507841\n",
      "Iteration 65, loss = 0.00454648\n",
      "Validation score: 0.510633\n",
      "Iteration 66, loss = 0.00454276\n",
      "Validation score: 0.509729\n",
      "Iteration 67, loss = 0.00454658\n",
      "Validation score: 0.511503\n",
      "Iteration 68, loss = 0.00454132\n",
      "Validation score: 0.508995\n",
      "Iteration 69, loss = 0.00453798\n",
      "Validation score: 0.493492\n",
      "Iteration 70, loss = 0.00453986\n",
      "Validation score: 0.504197\n",
      "Iteration 71, loss = 0.00454089\n",
      "Validation score: 0.511438\n",
      "Iteration 72, loss = 0.00453940\n",
      "Validation score: 0.509519\n",
      "Iteration 73, loss = 0.00453693\n",
      "Validation score: 0.510517\n",
      "Iteration 74, loss = 0.00453448\n",
      "Validation score: 0.501514\n",
      "Iteration 75, loss = 0.00453564\n",
      "Validation score: 0.505572\n",
      "Iteration 76, loss = 0.00453272\n",
      "Validation score: 0.509570\n",
      "Iteration 77, loss = 0.00453223\n",
      "Validation score: 0.513263\n",
      "Iteration 78, loss = 0.00453294\n",
      "Validation score: 0.513796\n",
      "Iteration 79, loss = 0.00453207\n",
      "Validation score: 0.514458\n",
      "Iteration 80, loss = 0.00452903\n",
      "Validation score: 0.503678\n",
      "Iteration 81, loss = 0.00453249\n",
      "Validation score: 0.501566\n",
      "Iteration 82, loss = 0.00453006\n",
      "Validation score: 0.504512\n",
      "Iteration 83, loss = 0.00453116\n",
      "Validation score: 0.514654\n",
      "Iteration 84, loss = 0.00452537\n",
      "Validation score: 0.515120\n",
      "Iteration 85, loss = 0.00452616\n",
      "Validation score: 0.505409\n",
      "Iteration 86, loss = 0.00452605\n",
      "Validation score: 0.513376\n",
      "Iteration 87, loss = 0.00452591\n",
      "Validation score: 0.515466\n",
      "Iteration 88, loss = 0.00452180\n",
      "Validation score: 0.510730\n",
      "Iteration 89, loss = 0.00452408\n",
      "Validation score: 0.506601\n",
      "Iteration 90, loss = 0.00451986\n",
      "Validation score: 0.502168\n",
      "Iteration 91, loss = 0.00452244\n",
      "Validation score: 0.506582\n",
      "Iteration 92, loss = 0.00451837\n",
      "Validation score: 0.513771\n",
      "Iteration 93, loss = 0.00451999\n",
      "Validation score: 0.513039\n",
      "Iteration 94, loss = 0.00451792\n",
      "Validation score: 0.515468\n",
      "Iteration 95, loss = 0.00451873\n",
      "Validation score: 0.506348\n",
      "Iteration 96, loss = 0.00451780\n",
      "Validation score: 0.516716\n",
      "Iteration 97, loss = 0.00451720\n",
      "Validation score: 0.503129\n",
      "Iteration 98, loss = 0.00451885\n",
      "Validation score: 0.509915\n",
      "Iteration 99, loss = 0.00451461\n",
      "Validation score: 0.511792\n",
      "Iteration 100, loss = 0.00451258\n",
      "Validation score: 0.513442\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrewt/miniconda3/envs/vesai/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5085365762922103"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "cri_pred_mlp_li = pd.Series(regr_li_et_al.predict(scaler.transform(X_test))).clip(0,1).values\n",
    "print(f'MAE: {mean_absolute_error(y_test, cri_pred_mlp_li)}')\n",
    "print(f'RMSE: {mean_squared_error(y_test, cri_pred_mlp_li, squared=False)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 0.04764371186450534\n",
      "RMSE: 0.0934240406219107\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from joblib import dump, load\n",
    "dump(regr_li_et_al, './data/li-et-al-mlp-vcra-v2.joblib') "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./data/li-et-al-mlp-vcra-v2.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def ml_calc_cri_li_etal(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    ves_dcpa, ves_tcpa, hr, rel_movement_angle, dist_euclid, speed_r = cri.colregs_alarms(own=own, target=target)\n",
    "    \n",
    "    return dist_euclid, [speed_r, hr, rel_movement_angle, dist_euclid]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "%%timeit \n",
    "ml_calc_cri_timeslice(l.copy(), model=regr_li_et_al, model_fun=ml_calc_cri_li_etal, model_norm=scaler);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "314 ms ± 2.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare with Gang et al."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "X = mlp_input[['own_course', 'target_course', 'own_speed', 'target_speed', 'hr', 'dist_euclid']].values\n",
    "y = mlp_input[['cri']].values.ravel()\n",
    "\n",
    "n_samples = 100000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train[:n_samples])\n",
    "\n",
    "regr_gang_et_al = SVR(verbose=True).fit(X_train_norm, y_train[:n_samples])\n",
    "\n",
    "regr_gang_et_al.score(scaler.transform(X_test[:n_samples]), y_test[:n_samples])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LibSVM].......................\n",
      "Warning: using -h 0 may be faster\n",
      "*.....................\n",
      "Warning: using -h 0 may be faster\n",
      "*..\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 46028\n",
      "obj = -1207.474944, rho = -0.221510\n",
      "nSV = 9729, nBSV = 9294\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4756252220748458"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "cri_pred_svm_gang = pd.Series(regr_gang_et_al.predict(scaler.transform(X_test[:n_samples]))).clip(0,1).values\n",
    "print(f'MAE: {mean_absolute_error(y_test[:n_samples], cri_pred_svm_gang)}')\n",
    "print(f'RMSE: {mean_squared_error(y_test[:n_samples], cri_pred_svm_gang, squared=False)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 0.057229761297088434\n",
      "RMSE: 0.09454195065998014\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from joblib import dump, load\n",
    "dump(regr_gang_et_al, './data/gang-et-al-svm-vcra-v2.joblib') "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./data/gang-et-al-svm-vcra-v2.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "def ml_calc_cri_gang_etal(rec_own, rec_target):\n",
    "    own = rec_own._asdict()\n",
    "    target = rec_target._asdict()\n",
    "    \n",
    "    own_geom_nm, target_geom_nm = map(helper.angular_to_nautical_miles, [own['geom'], target['geom']])\n",
    "    xr, yr = helper.calculate_delta(own_geom_nm.x, target_geom_nm.x), helper.calculate_delta(own_geom_nm.y, target_geom_nm.y)\n",
    "    hr = helper.calculate_delta(own['course'], target['course'])\n",
    "    \n",
    "    # Get vessels' Euclidean Distance -- NAUTICAL MILES\n",
    "    dist_euclid = np.sqrt(xr**2 + yr**2)\n",
    "    \n",
    "    return dist_euclid, [own['course'], target['course'], own['speed'], target['speed'], hr, dist_euclid]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "%%timeit \n",
    "ml_calc_cri_timeslice(l.copy(), model=regr_gang_et_al, model_fun=ml_calc_cri_gang_etal, model_norm=scaler);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "351 ms ± 1.45 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26a0fb21edfd8898ccaa2d3be90ad05e47a6ebc73217c056c6f09f953e946973"
  },
  "kernelspec": {
   "display_name": "Python (VesselAI)",
   "language": "python",
   "name": "vesai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}